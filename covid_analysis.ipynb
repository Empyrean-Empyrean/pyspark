{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8b614e-fdf8-43c2-83cf-ed2c9ba6eaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/17 21:01:50 WARN Utils: Your hostname, sridhar resolves to a loopback address: 127.0.1.1; using 172.18.174.89 instead (on interface wlp1s0)\n",
      "25/01/17 21:01:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/17 21:01:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession is active and ready to use.\n"
     ]
    }
   ],
   "source": [
    "import findspark \n",
    "findspark.init() \n",
    "from pyspark.sql import SparkSession  \n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DateType\n",
    "import pandas as pd  \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"COVID-19 Data Analysis\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "if 'spark' in locals() and isinstance(spark, SparkSession):\n",
    "    print(\"SparkSession is active and ready to use.\")\n",
    "else:\n",
    "    print(\"SparkSession is not active. Please create a SparkSession.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb7711c-724a-44ed-925a-320d719dbfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccination_data = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/KpHDlIzdtR63BdTofl1mOg/owid-covid-latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da45643b-75f1-405a-80a3-1ab1b5a05741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the first 5 records of the vaccination data:\n",
      "  continent  total_cases  total_deaths  total_vaccinations    population\n",
      "0      Asia     235214.0        7998.0                 NaN  4.112877e+07\n",
      "1       NaN   13145380.0      259117.0                 NaN  1.426737e+09\n",
      "2    Europe     335047.0        3605.0                 NaN  2.842318e+06\n",
      "3    Africa     272139.0        6881.0                 NaN  4.490323e+07\n",
      "4   Oceania       8359.0          34.0                 NaN  4.429500e+04\n"
     ]
    }
   ],
   "source": [
    "print(\"Displaying the first 5 records of the vaccination data:\")\n",
    "columns_to_display = ['continent', 'total_cases', 'total_deaths', 'total_vaccinations', 'population']\n",
    "print(vaccination_data[columns_to_display].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4b6be0-7a61-4d51-8956-a0e448349547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+----------+\n",
      "|    continent|total_cases|total_deaths|total_vaccinations|population|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "|         Asia|     235214|        7998|                 0|  41128772|\n",
      "|          nan|   13145380|      259117|                 0|1426736614|\n",
      "|       Europe|     335047|        3605|                 0|   2842318|\n",
      "|       Africa|     272139|        6881|                 0|  44903228|\n",
      "|      Oceania|       8359|          34|                 0|     44295|\n",
      "|       Europe|      48015|         159|                 0|     79843|\n",
      "|       Africa|     107481|        1937|                 0|  35588996|\n",
      "|North America|       3904|          12|                 0|     15877|\n",
      "|North America|       9106|         146|                 0|     93772|\n",
      "|South America|   10101218|      130663|                 0|  45510324|\n",
      "|         Asia|     452273|        8777|                 0|   2780472|\n",
      "|North America|      44224|         292|                 0|    106459|\n",
      "|          nan|  301499099|     1637249|        9104304615|4721383370|\n",
      "|      Oceania|   11861161|       25236|                 0|  26177410|\n",
      "|       Europe|    6082444|       22534|                 0|   8939617|\n",
      "|         Asia|     835757|       10353|                 0|  10358078|\n",
      "|North America|      39127|         849|                 0|    409989|\n",
      "|         Asia|     696614|        1536|                 0|   1472237|\n",
      "|         Asia|    2051348|       29499|                 0| 171186368|\n",
      "|North America|     108582|         593|                 0|    281646|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"continent\", StringType(), True),\n",
    "    StructField(\"total_cases\", LongType(), True),\n",
    "    StructField(\"total_deaths\", LongType(), True),\n",
    "    StructField(\"total_vaccinations\", LongType(), True),\n",
    "    StructField(\"population\", LongType(), True)\n",
    "])\n",
    "\n",
    "vaccination_data['continent'] = vaccination_data['continent'].astype(str)  # Ensures continent is a string\n",
    "vaccination_data['total_cases'] = vaccination_data['total_cases'].fillna(0).astype('int64')  # Fill NaNs and convert to int\n",
    "vaccination_data['total_deaths'] = vaccination_data['total_deaths'].fillna(0).astype('int64')  # Fill NaNs and convert to int\n",
    "vaccination_data['total_vaccinations'] = vaccination_data['total_vaccinations'].fillna(0).astype('int64')  # Fill NaNs and convert to int\n",
    "vaccination_data['population'] = vaccination_data['population'].fillna(0).astype('int64')  # Fill NaNs and convert to int\n",
    "\n",
    "spark_df = spark.createDataFrame(vaccination_data[schema.fieldNames()])  # Use only the specified fields\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d37a102-5f74-4315-a388-813e6cebff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the Spark DataFrame:\n",
      "root\n",
      " |-- continent: string (nullable = true)\n",
      " |-- total_cases: long (nullable = true)\n",
      " |-- total_deaths: long (nullable = true)\n",
      " |-- total_vaccinations: long (nullable = true)\n",
      " |-- population: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Schema of the Spark DataFrame:\")\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453f1376-f4a3-4bed-ac08-7447b73bffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+------------------+----------+\n",
      "|continent|total_cases|total_deaths|total_vaccinations|population|\n",
      "+---------+-----------+------------+------------------+----------+\n",
      "|     Asia|     235214|        7998|                 0|  41128772|\n",
      "|      nan|   13145380|      259117|                 0|1426736614|\n",
      "|   Europe|     335047|        3605|                 0|   2842318|\n",
      "|   Africa|     272139|        6881|                 0|  44903228|\n",
      "|  Oceania|       8359|          34|                 0|     44295|\n",
      "+---------+-----------+------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_display = ['continent', 'total_cases', 'total_deaths', 'total_vaccinations', 'population']\n",
    "spark_df.select(columns_to_display).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1097e45-15c9-476b-ad9a-c949bf2493b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the 'continent' and 'total_cases' columns:\n",
      "+---------+-----------+\n",
      "|continent|total_cases|\n",
      "+---------+-----------+\n",
      "|     Asia|     235214|\n",
      "|      nan|   13145380|\n",
      "|   Europe|     335047|\n",
      "|   Africa|     272139|\n",
      "|  Oceania|       8359|\n",
      "+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Displaying the 'continent' and 'total_cases' columns:\")\n",
    "spark_df.select('continent', 'total_cases').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebaa8d7a-56c0-49da-a76c-e66d2b5996e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering records where 'total_cases' is greater than 1,000,000:\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "|    continent|total_cases|total_deaths|total_vaccinations|population|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "|          nan|   13145380|      259117|                 0|1426736614|\n",
      "|South America|   10101218|      130663|                 0|  45510324|\n",
      "|          nan|  301499099|     1637249|        9104304615|4721383370|\n",
      "|      Oceania|   11861161|       25236|                 0|  26177410|\n",
      "|       Europe|    6082444|       22534|                 0|   8939617|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtering records where 'total_cases' is greater than 1,000,000:\")\n",
    "spark_df.filter(spark_df['total_cases'] > 1000000).show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780d35f1-9f57-40bb-a320-3fc0925f139e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------------+---------+------------------+-----------+\n",
      "|total_deaths|population|death_percentage|continent|total_vaccinations|total_cases|\n",
      "+------------+----------+----------------+---------+------------------+-----------+\n",
      "|        7998|  41128772|           0.02%|     Asia|                 0|     235214|\n",
      "|      259117|1426736614|           0.02%|      nan|                 0|   13145380|\n",
      "|        3605|   2842318|           0.13%|   Europe|                 0|     335047|\n",
      "|        6881|  44903228|           0.02%|   Africa|                 0|     272139|\n",
      "|          34|     44295|           0.08%|  Oceania|                 0|       8359|\n",
      "+------------+----------+----------------+---------+------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark_df_with_percentage = spark_df.withColumn(\n",
    "    'death_percentage', \n",
    "    (spark_df['total_deaths'] / spark_df['population']) * 100\n",
    ")\n",
    "spark_df_with_percentage = spark_df_with_percentage.withColumn(\n",
    "    'death_percentage',\n",
    "    F.concat(\n",
    "        F.format_number(spark_df_with_percentage['death_percentage'], 2), \n",
    "        F.lit('%')  \n",
    "    )\n",
    ")\n",
    "columns_to_display = ['total_deaths', 'population', 'death_percentage', 'continent', 'total_vaccinations', 'total_cases']\n",
    "spark_df_with_percentage.select(columns_to_display).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba0ebf9e-3508-4ad8-aa3e-2b94259bf9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the total deaths per continent:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|    continent|sum(total_deaths)|\n",
      "+-------------+-----------------+\n",
      "|       Europe|          2102483|\n",
      "|       Africa|           259117|\n",
      "|          nan|         22430618|\n",
      "|North America|          1671178|\n",
      "|South America|          1354187|\n",
      "|      Oceania|            32918|\n",
      "|         Asia|          1637249|\n",
      "+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Calculating the total deaths per continent:\")\n",
    "spark_df.groupby(['continent']).agg({\"total_deaths\": \"SUM\"}).show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e057cca3-9188-4cc3-b408-71d7ce05a181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.convert_total_deaths(total_deaths)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def convert_total_deaths(total_deaths):\n",
    "    return total_deaths * 2\n",
    "\n",
    "spark.udf.register(\"convert_total_deaths\", convert_total_deaths, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05e7a3c7-d0d2-4692-a29b-226e7b426faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+----------------------+\n",
      "|    continent|total_deaths|converted_total_deaths|\n",
      "+-------------+------------+----------------------+\n",
      "|         Asia|        7998|                 15996|\n",
      "|          nan|      259117|                518234|\n",
      "|       Europe|        3605|                  7210|\n",
      "|       Africa|        6881|                 13762|\n",
      "|      Oceania|          34|                    68|\n",
      "|       Europe|         159|                   318|\n",
      "|       Africa|        1937|                  3874|\n",
      "|North America|          12|                    24|\n",
      "|North America|         146|                   292|\n",
      "|South America|      130663|                261326|\n",
      "|         Asia|        8777|                 17554|\n",
      "|North America|         292|                   584|\n",
      "|          nan|     1637249|               3274498|\n",
      "|      Oceania|       25236|                 50472|\n",
      "|       Europe|       22534|                 45068|\n",
      "|         Asia|       10353|                 20706|\n",
      "|North America|         849|                  1698|\n",
      "|         Asia|        1536|                  3072|\n",
      "|         Asia|       29499|                 58998|\n",
      "|North America|         593|                  1186|\n",
      "+-------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DROP VIEW IF EXISTS data_v\")\n",
    "spark_df.createTempView('data_v')\n",
    "spark.sql('SELECT continent, total_deaths, convert_total_deaths(total_deaths) as converted_total_deaths FROM data_v').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638d4aa8-8b05-4bbc-b6bd-5d449471a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+----------+\n",
      "|    continent|total_cases|total_deaths|total_vaccinations|population|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "|         Asia|     235214|        7998|                 0|  41128772|\n",
      "|          nan|   13145380|      259117|                 0|1426736614|\n",
      "|       Europe|     335047|        3605|                 0|   2842318|\n",
      "|       Africa|     272139|        6881|                 0|  44903228|\n",
      "|      Oceania|       8359|          34|                 0|     44295|\n",
      "|       Europe|      48015|         159|                 0|     79843|\n",
      "|       Africa|     107481|        1937|                 0|  35588996|\n",
      "|North America|       3904|          12|                 0|     15877|\n",
      "|North America|       9106|         146|                 0|     93772|\n",
      "|South America|   10101218|      130663|                 0|  45510324|\n",
      "|         Asia|     452273|        8777|                 0|   2780472|\n",
      "|North America|      44224|         292|                 0|    106459|\n",
      "|          nan|  301499099|     1637249|        9104304615|4721383370|\n",
      "|      Oceania|   11861161|       25236|                 0|  26177410|\n",
      "|       Europe|    6082444|       22534|                 0|   8939617|\n",
      "|         Asia|     835757|       10353|                 0|  10358078|\n",
      "|North America|      39127|         849|                 0|    409989|\n",
      "|         Asia|     696614|        1536|                 0|   1472237|\n",
      "|         Asia|    2051348|       29499|                 0| 171186368|\n",
      "|North America|     108582|         593|                 0|    281646|\n",
      "+-------------+-----------+------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM data_v').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c0b5b88-4128-4172-979b-8fd71010bc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying continent with total vaccinated more than 1 million:\n",
      "+-------------+\n",
      "|    continent|\n",
      "+-------------+\n",
      "|          nan|\n",
      "|North America|\n",
      "|       Europe|\n",
      "|       Europe|\n",
      "|          nan|\n",
      "|          nan|\n",
      "|          nan|\n",
      "|         Asia|\n",
      "|         Asia|\n",
      "|       Europe|\n",
      "|          nan|\n",
      "|         Asia|\n",
      "|      Oceania|\n",
      "|          nan|\n",
      "|          nan|\n",
      "|          nan|\n",
      "|          nan|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Displaying continent with total vaccinated more than 1 million:\")\n",
    "spark.sql(\"SELECT continent FROM data_v WHERE total_vaccinations > 1000000\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
